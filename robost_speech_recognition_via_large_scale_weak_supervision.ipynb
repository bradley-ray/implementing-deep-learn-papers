{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRruRSWDaiuTuD5OBDF6lj"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Robost Speech Recognition via Large Scale Weak Supervision\n",
        "\n",
        "- [whisper paper](https://arxiv.org/abs/2212.04356)\n",
        "- [openai github](https://github.com/openai/whisper)"
      ],
      "metadata": {
        "id": "v4c98eRp1wFK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "crejdxnr1jbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c756f681-7168-4c01-cae3-33b927226268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-22 16:02:52--  https://openaipublic.azureedge.net/main/whisper/models/d3dd57d32accea0b295c96e26691aa14d8822fac7d9d27d5dc00b4ca2826dd03/tiny.en.pt\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.253.40, 13.107.226.40, 2620:1ec:29:1::40, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.253.40|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75571315 (72M) [application/octet-stream]\n",
            "Saving to: ‘tiny.en.pt’\n",
            "\n",
            "tiny.en.pt          100%[===================>]  72.07M  33.5MB/s    in 2.2s    \n",
            "\n",
            "2023-01-22 16:02:54 (33.5 MB/s) - ‘tiny.en.pt’ saved [75571315/75571315]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# tiny multilingual model\n",
        "# !wget https://openaipublic.azureedge.net/main/whisper/models/65147644a518d12f04e32d6f3b26facc3f8dd46e5390956a9424a650c0ce22b9/tiny.pt\n",
        "# tiny english only model\n",
        "!wget https://openaipublic.azureedge.net/main/whisper/models/d3dd57d32accea0b295c96e26691aa14d8822fac7d9d27d5dc00b4ca2826dd03/tiny.en.pt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import math"
      ],
      "metadata": {
        "id": "tIKh51TD12Wm"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.load('tiny.en.pt')\n",
        "for layer in data['model_state_dict']:\n",
        "    print(data['model_state_dict'][layer].shape, layer)"
      ],
      "metadata": {
        "id": "kwiFCy27145E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be4f72f-98bf-42c5-a971-e9621884f8ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([448, 384]) decoder.positional_embedding\n",
            "torch.Size([1500, 384]) encoder.positional_embedding\n",
            "torch.Size([51864, 384]) decoder.token_embedding.weight\n",
            "torch.Size([384]) decoder.blocks.0.mlp_ln.weight\n",
            "torch.Size([384]) decoder.blocks.0.mlp_ln.bias\n",
            "torch.Size([1536, 384]) decoder.blocks.0.mlp.0.weight\n",
            "torch.Size([1536]) decoder.blocks.0.mlp.0.bias\n",
            "torch.Size([384, 1536]) decoder.blocks.0.mlp.2.weight\n",
            "torch.Size([384]) decoder.blocks.0.mlp.2.bias\n",
            "torch.Size([384]) decoder.blocks.0.attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.0.attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.0.attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.0.attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.0.attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.0.attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.0.attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.0.attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.0.attn.out.bias\n",
            "torch.Size([384]) decoder.blocks.0.cross_attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.0.cross_attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.0.cross_attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.0.cross_attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.0.cross_attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.0.cross_attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.0.cross_attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.0.cross_attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.0.cross_attn.out.bias\n",
            "torch.Size([384]) decoder.blocks.1.mlp_ln.weight\n",
            "torch.Size([384]) decoder.blocks.1.mlp_ln.bias\n",
            "torch.Size([1536, 384]) decoder.blocks.1.mlp.0.weight\n",
            "torch.Size([1536]) decoder.blocks.1.mlp.0.bias\n",
            "torch.Size([384, 1536]) decoder.blocks.1.mlp.2.weight\n",
            "torch.Size([384]) decoder.blocks.1.mlp.2.bias\n",
            "torch.Size([384]) decoder.blocks.1.attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.1.attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.1.attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.1.attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.1.attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.1.attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.1.attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.1.attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.1.attn.out.bias\n",
            "torch.Size([384]) decoder.blocks.1.cross_attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.1.cross_attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.1.cross_attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.1.cross_attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.1.cross_attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.1.cross_attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.1.cross_attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.1.cross_attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.1.cross_attn.out.bias\n",
            "torch.Size([384]) decoder.blocks.2.mlp_ln.weight\n",
            "torch.Size([384]) decoder.blocks.2.mlp_ln.bias\n",
            "torch.Size([1536, 384]) decoder.blocks.2.mlp.0.weight\n",
            "torch.Size([1536]) decoder.blocks.2.mlp.0.bias\n",
            "torch.Size([384, 1536]) decoder.blocks.2.mlp.2.weight\n",
            "torch.Size([384]) decoder.blocks.2.mlp.2.bias\n",
            "torch.Size([384]) decoder.blocks.2.attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.2.attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.2.attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.2.attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.2.attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.2.attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.2.attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.2.attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.2.attn.out.bias\n",
            "torch.Size([384]) decoder.blocks.2.cross_attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.2.cross_attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.2.cross_attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.2.cross_attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.2.cross_attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.2.cross_attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.2.cross_attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.2.cross_attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.2.cross_attn.out.bias\n",
            "torch.Size([384]) decoder.blocks.3.mlp_ln.weight\n",
            "torch.Size([384]) decoder.blocks.3.mlp_ln.bias\n",
            "torch.Size([1536, 384]) decoder.blocks.3.mlp.0.weight\n",
            "torch.Size([1536]) decoder.blocks.3.mlp.0.bias\n",
            "torch.Size([384, 1536]) decoder.blocks.3.mlp.2.weight\n",
            "torch.Size([384]) decoder.blocks.3.mlp.2.bias\n",
            "torch.Size([384]) decoder.blocks.3.attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.3.attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.3.attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.3.attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.3.attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.3.attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.3.attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.3.attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.3.attn.out.bias\n",
            "torch.Size([384]) decoder.blocks.3.cross_attn_ln.weight\n",
            "torch.Size([384]) decoder.blocks.3.cross_attn_ln.bias\n",
            "torch.Size([384, 384]) decoder.blocks.3.cross_attn.query.weight\n",
            "torch.Size([384]) decoder.blocks.3.cross_attn.query.bias\n",
            "torch.Size([384, 384]) decoder.blocks.3.cross_attn.key.weight\n",
            "torch.Size([384, 384]) decoder.blocks.3.cross_attn.value.weight\n",
            "torch.Size([384]) decoder.blocks.3.cross_attn.value.bias\n",
            "torch.Size([384, 384]) decoder.blocks.3.cross_attn.out.weight\n",
            "torch.Size([384]) decoder.blocks.3.cross_attn.out.bias\n",
            "torch.Size([384]) decoder.ln.weight\n",
            "torch.Size([384]) decoder.ln.bias\n",
            "torch.Size([384, 80, 3]) encoder.conv1.weight\n",
            "torch.Size([384]) encoder.conv1.bias\n",
            "torch.Size([384, 384, 3]) encoder.conv2.weight\n",
            "torch.Size([384]) encoder.conv2.bias\n",
            "torch.Size([384]) encoder.blocks.0.mlp_ln.weight\n",
            "torch.Size([384]) encoder.blocks.0.mlp_ln.bias\n",
            "torch.Size([1536, 384]) encoder.blocks.0.mlp.0.weight\n",
            "torch.Size([1536]) encoder.blocks.0.mlp.0.bias\n",
            "torch.Size([384, 1536]) encoder.blocks.0.mlp.2.weight\n",
            "torch.Size([384]) encoder.blocks.0.mlp.2.bias\n",
            "torch.Size([384]) encoder.blocks.0.attn_ln.weight\n",
            "torch.Size([384]) encoder.blocks.0.attn_ln.bias\n",
            "torch.Size([384, 384]) encoder.blocks.0.attn.query.weight\n",
            "torch.Size([384]) encoder.blocks.0.attn.query.bias\n",
            "torch.Size([384, 384]) encoder.blocks.0.attn.key.weight\n",
            "torch.Size([384, 384]) encoder.blocks.0.attn.value.weight\n",
            "torch.Size([384]) encoder.blocks.0.attn.value.bias\n",
            "torch.Size([384, 384]) encoder.blocks.0.attn.out.weight\n",
            "torch.Size([384]) encoder.blocks.0.attn.out.bias\n",
            "torch.Size([384]) encoder.blocks.1.mlp_ln.weight\n",
            "torch.Size([384]) encoder.blocks.1.mlp_ln.bias\n",
            "torch.Size([1536, 384]) encoder.blocks.1.mlp.0.weight\n",
            "torch.Size([1536]) encoder.blocks.1.mlp.0.bias\n",
            "torch.Size([384, 1536]) encoder.blocks.1.mlp.2.weight\n",
            "torch.Size([384]) encoder.blocks.1.mlp.2.bias\n",
            "torch.Size([384]) encoder.blocks.1.attn_ln.weight\n",
            "torch.Size([384]) encoder.blocks.1.attn_ln.bias\n",
            "torch.Size([384, 384]) encoder.blocks.1.attn.query.weight\n",
            "torch.Size([384]) encoder.blocks.1.attn.query.bias\n",
            "torch.Size([384, 384]) encoder.blocks.1.attn.key.weight\n",
            "torch.Size([384, 384]) encoder.blocks.1.attn.value.weight\n",
            "torch.Size([384]) encoder.blocks.1.attn.value.bias\n",
            "torch.Size([384, 384]) encoder.blocks.1.attn.out.weight\n",
            "torch.Size([384]) encoder.blocks.1.attn.out.bias\n",
            "torch.Size([384]) encoder.blocks.2.mlp_ln.weight\n",
            "torch.Size([384]) encoder.blocks.2.mlp_ln.bias\n",
            "torch.Size([1536, 384]) encoder.blocks.2.mlp.0.weight\n",
            "torch.Size([1536]) encoder.blocks.2.mlp.0.bias\n",
            "torch.Size([384, 1536]) encoder.blocks.2.mlp.2.weight\n",
            "torch.Size([384]) encoder.blocks.2.mlp.2.bias\n",
            "torch.Size([384]) encoder.blocks.2.attn_ln.weight\n",
            "torch.Size([384]) encoder.blocks.2.attn_ln.bias\n",
            "torch.Size([384, 384]) encoder.blocks.2.attn.query.weight\n",
            "torch.Size([384]) encoder.blocks.2.attn.query.bias\n",
            "torch.Size([384, 384]) encoder.blocks.2.attn.key.weight\n",
            "torch.Size([384, 384]) encoder.blocks.2.attn.value.weight\n",
            "torch.Size([384]) encoder.blocks.2.attn.value.bias\n",
            "torch.Size([384, 384]) encoder.blocks.2.attn.out.weight\n",
            "torch.Size([384]) encoder.blocks.2.attn.out.bias\n",
            "torch.Size([384]) encoder.blocks.3.mlp_ln.weight\n",
            "torch.Size([384]) encoder.blocks.3.mlp_ln.bias\n",
            "torch.Size([1536, 384]) encoder.blocks.3.mlp.0.weight\n",
            "torch.Size([1536]) encoder.blocks.3.mlp.0.bias\n",
            "torch.Size([384, 1536]) encoder.blocks.3.mlp.2.weight\n",
            "torch.Size([384]) encoder.blocks.3.mlp.2.bias\n",
            "torch.Size([384]) encoder.blocks.3.attn_ln.weight\n",
            "torch.Size([384]) encoder.blocks.3.attn_ln.bias\n",
            "torch.Size([384, 384]) encoder.blocks.3.attn.query.weight\n",
            "torch.Size([384]) encoder.blocks.3.attn.query.bias\n",
            "torch.Size([384, 384]) encoder.blocks.3.attn.key.weight\n",
            "torch.Size([384, 384]) encoder.blocks.3.attn.value.weight\n",
            "torch.Size([384]) encoder.blocks.3.attn.value.bias\n",
            "torch.Size([384, 384]) encoder.blocks.3.attn.out.weight\n",
            "torch.Size([384]) encoder.blocks.3.attn.out.bias\n",
            "torch.Size([384]) encoder.ln_post.weight\n",
            "torch.Size([384]) encoder.ln_post.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttn(nn.Module):\n",
        "    def __init__(self, emb_dim, num_heads):\n",
        "        super().__init__()\n",
        "        assert(emb_dim % num_heads == 0)\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.query = nn.Linear(emb_dim, emb_dim)\n",
        "        # why no bias for key?\n",
        "        self.key = nn.Linear(emb_dim, emb_dim, bias=False)\n",
        "        self.value = nn.Linear(emb_dim, emb_dim)\n",
        "        self.out = nn.Linear(emb_dim, emb_dim)\n",
        "        self.scores = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (bs, seq_len, emb_dim) -> (bs, seq_len, num_heads, head_size)\n",
        "        q, k, v = [y(x).reshape(x.shape[0], -1, \n",
        "                                self.num_heads, self.emb_dim//self.num_heads)\n",
        "                    for y in [self.query, self.key, self.value]]\n",
        "        # (bs, num_heads, seq_len, head_size)\n",
        "        q, k, v = [y.permute(0, 2, 1, 3) for y in [q, k, v]]\n",
        "        out = q @ k.transpose(-2, -1) * (1/math.sqrt(q.shape[-1]))\n",
        "        out = torch.softmax(out, dim=-1)\n",
        "        self.scores = out.clone()\n",
        "        # back to (bs, seq_len, emb_dim)\n",
        "        out = (out @ v).permute(0, 2, 1, 3)\n",
        "        out = out.reshape(x.shape[0], -1, self.emb_dim)\n",
        "        out = self.out(out)\n",
        "        return out\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.ff1 = nn.Linear(emb_dim, 1536)\n",
        "        self.ff2 = nn.Linear(1536, emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.droupout(F.gelu(self.ff1), probability=0.1, train=False)\n",
        "        x = F.droupout(self.ff2, probability=0.1, train=False)\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, in_ch, emb_dim, num_heads):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttn(emb_dim, num_heads)\n",
        "        self.norm1 = nn.LayerNorm(emb_dim)\n",
        "        self.mlp = MLPBlock(emb_dim)\n",
        "        self.norm2 = nn.LayerNorm(emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm1(x)\n",
        "        x = self.attn(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.mlp(x)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, in_ch, emb_dim, num_heads, num_encs):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.num_encs = num_encs\n",
        "        self.emb = nn.Sequential(*[\n",
        "            nn.Conv1d(in_ch, emb_dim, kernel_size=3, padding=1),\n",
        "            nn.GELU(),\n",
        "            nn.Conv1d(emb_dim, emb_dim, kernel_size=3, stride=2, padding=1),\n",
        "            nn.GELU(),\n",
        "        ])\n",
        "        # not implementing sin_pos_emb b/c \n",
        "        # pretrained weights already provide pos_emb values\n",
        "        self.register_buffer('pos_emb', tensor=torch.zeros((1500,384)))\n",
        "        self.model = nn.Sequential(*[\n",
        "            EncoderBlock(in_ch, emb_dim, num_heads)\n",
        "            for _ in range(num_encs)\n",
        "        ])\n",
        "\n",
        "        self.norm = nn.LayerNorm(emb_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x) + self.pos_emb\n",
        "        x = self.model(x)\n",
        "        x = self.norm(x)\n",
        "        return x\n",
        "\n",
        "    def load_pretrained_model(self, path):\n",
        "        pretrained = torch.load(path)['model_state_dict']\n",
        "        params = self.state_dict()\n",
        "        params['emb.0.weight'] = pretrained['encoder.conv1.weight']\n",
        "        params['emb.0.bias'] = pretrained['encoder.conv1.bias']\n",
        "        params['emb.2.weight'] = pretrained['encoder.conv2.weight']\n",
        "        params['emb.2.bias'] = pretrained['encoder.conv2.bias']\n",
        "        params['pos_emb'] = pretrained['encoder.positional_embedding']\n",
        "        params['norm.weight'] = pretrained['encoder.ln_post.weight']\n",
        "        params['norm.bias'] = pretrained['encoder.ln_post.weight']\n",
        "        for i in range(self.num_encs):\n",
        "            params[f'model.{i}.attn.query.weight'] = pretrained[f'encoder.blocks.{i}.attn.query.weight']\n",
        "            params[f'model.{i}.attn.query.bias'] = pretrained[f'encoder.blocks.{i}.attn.query.bias']\n",
        "            params[f'model.{i}.attn.key.weight'] = pretrained[f'encoder.blocks.{i}.attn.key.weight']\n",
        "            params[f'model.{i}.attn.value.weight'] = pretrained[f'encoder.blocks.{i}.attn.value.weight']\n",
        "            params[f'model.{i}.attn.value.bias'] = pretrained[f'encoder.blocks.{i}.attn.value.bias']\n",
        "            params[f'model.{i}.attn.out.weight'] = pretrained[f'encoder.blocks.{i}.attn.out.weight']\n",
        "            params[f'model.{i}.attn.out.bias'] = pretrained[f'encoder.blocks.{i}.attn.out.bias']\n",
        "            params[f'model.{i}.norm1.weight'] = pretrained[f'encoder.blocks.{i}.attn_ln.weight']\n",
        "            params[f'model.{i}.norm1.bias'] = pretrained[f'encoder.blocks.{i}.attn_ln.bias']\n",
        "            params[f'model.{i}.mlp.ff1.weight'] = pretrained[f'encoder.blocks.{i}.mlp.0.weight']\n",
        "            params[f'model.{i}.mlp.ff1.bias'] = pretrained[f'encoder.blocks.{i}.mlp.0.bias']\n",
        "            params[f'model.{i}.mlp.ff2.weight'] = pretrained[f'encoder.blocks.{i}.mlp.2.weight']\n",
        "            params[f'model.{i}.mlp.ff2.bias'] = pretrained[f'encoder.blocks.{i}.mlp.2.bias']\n",
        "            params[f'model.{i}.norm2.weight'] = pretrained[f'encoder.blocks.{i}.mlp_ln.weight']\n",
        "            params[f'model.{i}.norm2.bias'] = pretrained[f'encoder.blocks.{i}.mlp_ln.bias']\n",
        "        self.load_state_dict(params)"
      ],
      "metadata": {
        "id": "ty4fCK7B18ya"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(80, 384, 6, 4)\n",
        "encoder.load_pretrained_model('tiny.en.pt')"
      ],
      "metadata": {
        "id": "gDoPN6b8OFtx"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}