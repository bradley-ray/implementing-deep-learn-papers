{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNy+/7pHPe6ZBsCCsrbdgvx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install sacremoses"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tjuj16kO5bBv",
        "outputId": "c73b2660-01a5-4c1b-a2d5-b5a435804f4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 19.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacremoses) (2022.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sacremoses) (4.64.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d32c7bee2caf09a277d52b7689bd520d401d7efc6f67e2d14758b6394f665950\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.0.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hb1o6IFg5URr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import os\n",
        "\n",
        "import torchtext.transforms as T\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "from torchtext.vocab import vocab\n",
        "from collections import OrderedDict\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb = nn.Embedding(10, 5)"
      ],
      "metadata": {
        "id": "iIjhMY6M6svH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randint(0,10,(2,10),dtype=torch.int64)\n",
        "emb(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHi5B7R16w_4",
        "outputId": "b86c46ba-bf70-498b-fbb1-521cb5431094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.2831,  0.3242,  0.9459, -1.7871,  0.2675],\n",
              "         [-0.1369,  0.1705, -0.0410,  1.3350,  1.3271],\n",
              "         [-1.0412,  1.2759, -0.1053, -0.0850, -1.1732],\n",
              "         [-1.8657,  0.0713,  0.1171,  0.2328,  1.4423],\n",
              "         [ 1.2831,  0.3242,  0.9459, -1.7871,  0.2675],\n",
              "         [-0.1800, -0.8466, -0.1904, -1.0192,  2.6787],\n",
              "         [-1.0412,  1.2759, -0.1053, -0.0850, -1.1732],\n",
              "         [-1.0412,  1.2759, -0.1053, -0.0850, -1.1732],\n",
              "         [-1.9008, -1.2194,  0.1945, -0.5162,  0.2388],\n",
              "         [-1.9008, -1.2194,  0.1945, -0.5162,  0.2388]],\n",
              "\n",
              "        [[-1.0412,  1.2759, -0.1053, -0.0850, -1.1732],\n",
              "         [ 0.0444,  1.2466, -0.1850, -0.3290, -2.6041],\n",
              "         [-0.1800, -0.8466, -0.1904, -1.0192,  2.6787],\n",
              "         [-0.1369,  0.1705, -0.0410,  1.3350,  1.3271],\n",
              "         [ 0.0444,  1.2466, -0.1850, -0.3290, -2.6041],\n",
              "         [ 0.0444,  1.2466, -0.1850, -0.3290, -2.6041],\n",
              "         [-1.0412,  1.2759, -0.1053, -0.0850, -1.1732],\n",
              "         [-1.9721, -1.0152,  0.3521,  0.2212,  0.6922],\n",
              "         [-1.9721, -1.0152,  0.3521,  0.2212,  0.6922],\n",
              "         [ 1.2831,  0.3242,  0.9459, -1.7871,  0.2675]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.statmt.org/europarl/v7/fr-en.tgz\n",
        "!tar xfz *.tgz\n",
        "!mkdir -p data/training\n",
        "!mv *.en *.fr data/training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-3jCgcw77wD",
        "outputId": "975ffd0b-84c5-48a6-e2f4-360a03c945f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-05 17:56:43--  https://www.statmt.org/europarl/v7/fr-en.tgz\n",
            "Resolving www.statmt.org (www.statmt.org)... 129.215.197.184\n",
            "Connecting to www.statmt.org (www.statmt.org)|129.215.197.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 202718517 (193M) [application/x-gzip]\n",
            "Saving to: ‘fr-en.tgz’\n",
            "\n",
            "fr-en.tgz           100%[===================>] 193.33M  1.54MB/s    in 1m 49s  \n",
            "\n",
            "2022-11-05 17:58:32 (1.77 MB/s) - ‘fr-en.tgz’ saved [202718517/202718517]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: need to clean and speed this up, but for now it works fine\n",
        "def get_phrases(path, tokenizer, size):\n",
        "    phrases = []\n",
        "    en_tokenize = get_tokenizer(tokenizer, language='en')\n",
        "    fr_tokenize = get_tokenizer(tokenizer, language='fr')\n",
        "    # get tokenized dataset\n",
        "    with open(f'{path}/europarl-v7.fr-en.en') as en:\n",
        "        with open(f'{path}/europarl-v7.fr-en.fr') as fr:\n",
        "            k = 0\n",
        "            for phrase in zip(en.readlines(), fr.readlines()):\n",
        "                en_phrase = en_tokenize(phrase[0].strip())\n",
        "                fr_phrase = fr_tokenize(phrase[1].strip())\n",
        "                phrases.append({\n",
        "                    'en': en_phrase,\n",
        "                    'fr': fr_phrase,\n",
        "                })\n",
        "                k+=1\n",
        "                if k >= size: break\n",
        "    return phrases\n",
        "\n",
        "def get_vocab(phrases, special_tokens):\n",
        "    vocab_freq_en = {}\n",
        "    vocab_freq_fr = {}\n",
        "\n",
        "    for phrase in phrases:\n",
        "        for word in phrase['en']:\n",
        "            vocab_freq_en[word] = vocab_freq_en.get(word, 0) + 1\n",
        "\n",
        "        for word in phrase['fr']:\n",
        "            vocab_freq_fr[word] = vocab_freq_fr.get(word, 0) + 1\n",
        "\n",
        "    vocab_en_ = sorted(vocab_freq_en.keys(), key=lambda x: vocab_freq_en[x], reverse=True)\n",
        "    vocab_fr_ = sorted(vocab_freq_fr.keys(), key=lambda x: vocab_freq_fr[x], reverse=True)\n",
        "\n",
        "    \n",
        "\n",
        "    vocab_en = vocab_en_[:15_000] + special_tokens\n",
        "    vocab_fr = vocab_fr_[:15_000] + special_tokens\n",
        "\n",
        "    vocab_en = vocab(OrderedDict([(word, 1) for word in vocab_en]))\n",
        "    vocab_en.set_default_index(-1)\n",
        "    vocab_fr = vocab(OrderedDict([(word, 1) for word in vocab_fr]))\n",
        "    vocab_fr.set_default_index(-1)\n",
        "\n",
        "    return vocab_en, vocab_fr\n",
        "\n",
        "\n",
        "def to_idx(phrases, vocab, special_tokens):\n",
        "    max_len = 0\n",
        "    idx_phrases = []\n",
        "    vocab_en, vocab_fr = vocab\n",
        "    for phrase in phrases:\n",
        "        phrase['en'] = special_tokens[:1] + phrase['en'] + special_tokens[1:2]\n",
        "        phrase['fr'] = special_tokens[:1] + phrase['fr'] + special_tokens[1:2]\n",
        "        if max_len < len(phrase['en']):\n",
        "            max_len = len(phrase['en'])\n",
        "        if max_len < len(phrase['fr']):\n",
        "            max_len = len(phrase['fr'])\n",
        "\n",
        "    for phrase in phrases:\n",
        "        en_phrase = phrase['en']\n",
        "        fr_phrase = phrase['fr']\n",
        "\n",
        "        en_phrase_idx = T.VocabTransform(vocab_en)(en_phrase)\n",
        "        fr_phrase_idx = T.VocabTransform(vocab_fr)(fr_phrase)\n",
        "\n",
        "        idx_phrases.append({\n",
        "            'en': en_phrase_idx,\n",
        "            'fr': fr_phrase_idx,\n",
        "        })\n",
        "    return idx_phrases, max_len\n",
        "\n",
        "class WMT2014(Dataset):\n",
        "    def __init__(self, path, special_tokens, show_idx=True):\n",
        "        self.path = path\n",
        "        self.show_idx = show_idx\n",
        "        self.special_tokens = special_tokens\n",
        "        self.phrases = get_phrases(self.path, 'moses', 100_000)\n",
        "        self.vocab = get_vocab(self.phrases, self.special_tokens)\n",
        "        self.idx_phrases, self.max_len = to_idx(self.phrases, self.vocab, self.special_tokens)\n",
        "\n",
        "    def __getitem__(self, idx) :\n",
        "        if self.show_idx:\n",
        "            padded_src = torch.zeros(self.max_len, dtype=torch.int32)\n",
        "            padded_tgt = torch.zeros(self.max_len, dtype=torch.int32)\n",
        "            src = torch.tensor(self.idx_phrases[idx]['en'])\n",
        "            tgt = torch.tensor(self.idx_phrases[idx]['fr'])\n",
        "\n",
        "            padded_src[:src.shape[0]] = src\n",
        "            padded_tgt[:tgt.shape[0]] = tgt\n",
        "\n",
        "            return padded_src, padded_tgt\n",
        "        else:\n",
        "            src = self.phrases[idx]['en']\n",
        "            tgt = self.phrases[idx]['fr']\n",
        "            return src, tgt\n",
        "        \n",
        "\n",
        "        return src, tgt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.phrases)"
      ],
      "metadata": {
        "id": "N58foGL87-oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = WMT2014('data/training', ['<SOS>', '<EOS>', '<UNK>'])"
      ],
      "metadata": {
        "id": "0htcaD1C8AgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds, batch_size=128, shuffle=True)"
      ],
      "metadata": {
        "id": "oTLaQwa-8DFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: add masking\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, seq_len, d_model, num_heads, mask=False):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.seq_len = seq_len\n",
        "        self.num_heads = num_heads\n",
        "        self.d_k = d_model // num_heads\n",
        "\n",
        "        self.w_q = nn.Linear(d_model, d_model)\n",
        "        self.w_k = nn.Linear(d_model, d_model)\n",
        "        self.w_v = nn.Linear(d_model, d_model)\n",
        "        self.w_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def reshape(self, x):\n",
        "        # [bs, seq_len, num_heads, d_k]\n",
        "        out = x.reshape(*x.shape[:2], self.num_heads, self.d_k)\n",
        "        # [bs, num_heads, seq_len, d_k]\n",
        "        return out.permute(0, 2, 1, 3)\n",
        "\n",
        "    def attention(self, q, k, v):\n",
        "        scale = 1 / self.d_k**0.5\n",
        "        out = q @ k.transpose(-2, -1) * scale\n",
        "        out = self.softmax(out) @ v\n",
        "        return out\n",
        "\n",
        "    def forward(self, q, k, v):\n",
        "        # [bs, num_heads, seq_len, d_k]\n",
        "        q = self.reshape(self.w_q(q))\n",
        "        k = self.reshape(self.w_k(k))\n",
        "        v = self.reshape(self.w_v(v))\n",
        "\n",
        "        # [bs, seq_len, num_heads, d_k]\n",
        "        attn = self.attention(q, v, k).permute(0, 2, 1, 3)\n",
        "        # [bs, seq_len, d_model]\n",
        "        attn = attn.reshape(-1, self.seq_len, self.d_model)\n",
        "\n",
        "        out = self.w_o(attn)\n",
        "\n",
        "        return out\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, seq_len, emb_dim):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        self.pe = torch.zeros(seq_len, emb_dim)\n",
        "        pos = torch.arange(seq_len).unsqueeze(1)\n",
        "        i = torch.arange(0, emb_dim, 2)\n",
        "        div = 1 / torch.pow(10000, i / emb_dim)\n",
        "        self.pe[:, 0::2] = torch.sin(pos*div)\n",
        "        self.pe[:, 1::2] = torch.cos(pos*div)\n",
        "\n",
        "        # give it batch dim\n",
        "        self.pe = self.pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, emb):\n",
        "        return emb + self.pe\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "    def __init__(self, seq_len, d_model, num_heads):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "\n",
        "        norm_shape = (seq_len, d_model)\n",
        "\n",
        "        self.attn = MultiHeadAttention(seq_len, d_model, num_heads)\n",
        "        self.ln_1 = nn.LayerNorm(norm_shape)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, d_model),\n",
        "        )\n",
        "\n",
        "        self.ln_2 = nn.LayerNorm(norm_shape)\n",
        "    \n",
        "    def forward(self, src):\n",
        "        attn = self.attn(src, src, src)\n",
        "        out_1 = self.ln_1(src + attn)\n",
        "\n",
        "        ff = self.ff(out_1)\n",
        "        out_2 = self.ln_2(out_1 + ff)\n",
        "\n",
        "        return out_2\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    def __init__(self, seq_len, d_model, num_heads):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        \n",
        "        norm_shape = (seq_len, d_model)\n",
        "\n",
        "        self.attn_1 = MultiHeadAttention(seq_len, d_model, num_heads)\n",
        "        self.ln_1 = nn.LayerNorm(norm_shape)\n",
        "\n",
        "        self.attn_2 = MultiHeadAttention(seq_len, d_model, num_heads)\n",
        "        self.ln_2 = nn.LayerNorm(norm_shape)\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d_model, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(2048, d_model),\n",
        "        )\n",
        "        self.ln_3 = nn.LayerNorm(norm_shape)\n",
        "\n",
        "    # TODO: find better solutions for decoder inputs\n",
        "    def forward(self, args):\n",
        "        enc = args[0]\n",
        "        tgt = args[1]\n",
        "\n",
        "        attn_1 = self.attn_1(tgt, tgt, tgt)\n",
        "        out_1 = self.ln_1(enc + attn_1)\n",
        "\n",
        "        attn_2 = self.attn_2(enc, enc, out_1)\n",
        "        out_2 = self.ln_2(out_1 + attn_2)\n",
        "\n",
        "        ff = self.ff(out_2)\n",
        "        out_3 = self.ln_3(out_2 + ff)\n",
        "\n",
        "        return enc, out_3\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, seq_len, vocab_len, d_model, num_blocks, num_heads):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.inp_emb = nn.Embedding(vocab_len, d_model)\n",
        "        self.out_emb = nn.Embedding(vocab_len, d_model)\n",
        "        self.pos_enc = PositionalEncoding(seq_len, d_model)\n",
        "\n",
        "        self.enc = nn.Sequential(\n",
        "            *[EncoderBlock(seq_len, d_model, num_heads) for _ in range(num_blocks)]\n",
        "        )\n",
        "\n",
        "        self.dec = nn.Sequential(\n",
        "            *[DecoderBlock(seq_len, d_model, num_heads) for _ in range(num_blocks)]\n",
        "        )\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            nn.Linear(d_model, vocab_len),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        inp_emb = self.pos_enc(self.inp_emb(src))\n",
        "        enc = self.enc(inp_emb)\n",
        "\n",
        "        out_emb = self.out_emb(tgt)\n",
        "        _, dec = self.dec((enc, out_emb))\n",
        "\n",
        "        out = self.out(dec)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "t5iFypqFG8k5"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = 10\n",
        "v = 128\n",
        "bs = 16\n",
        "nh = 8\n",
        "dm = 512\n",
        "nb = 6\n",
        "\n",
        "t = Transformer(s, v, dm, nb, nh)\n",
        "\n",
        "src = torch.randint(v, (bs, s))\n",
        "tgt = torch.randint(v, (bs, s))\n",
        "\n",
        "# inp_emb = nn.Embedding(v, dm)(src)\n",
        "# pe = PositionalEncoding(s, dm)(inp_emb)\n",
        "# enc = EncoderBlock(s, dm, nh)\n",
        "# dec = DecoderBlock(s, dm, nh)\n",
        "# dec((enc(pe), pe)).shape\n",
        "\n",
        "out = t(src, tgt)\n",
        "print(out.shape)\n",
        "out.argmax(dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiqn_IDm0Wxy",
        "outputId": "a63e9340-818f-4315-d53a-70bffc9ba936"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 10, 128])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[122,   7, 101,  62,  50, 103,  91, 103,   8, 122],\n",
              "        [124,  97, 103,  81,  41, 103,  81, 122,  91, 122],\n",
              "        [ 26, 103,  11, 122,  86,  44,  59,   1,  53, 122],\n",
              "        [ 23,  50,  25,  91, 102, 103, 122,  26,  46, 103],\n",
              "        [ 41,  26,  26,  26,   1,  41,  85,  64, 111,  41],\n",
              "        [103,  54,  26,  86,   1,  50,  68,  23, 103,  26],\n",
              "        [ 50,  31,  50, 122, 105,  52,  50,  50,   5,  50],\n",
              "        [ 50, 103,  26, 122,  11, 118, 101, 122, 122, 122],\n",
              "        [103,   1,  97, 124,  50,  50, 100,  26, 103,  26],\n",
              "        [103,  54,  52,  50, 122,  50,  54,  50, 122,  54],\n",
              "        [ 26,  26,  26,  26,  74, 111, 103,  50, 111, 122],\n",
              "        [ 31,  52,  97,  31, 103,  91,  54,  52,   5,  91],\n",
              "        [ 50,  46, 100, 100,   4,  12,  26, 103, 107,  26],\n",
              "        [122, 122, 122, 114, 122,  17,  59,  50,  54,   7],\n",
              "        [103,  58, 103, 103,  62,  62, 100, 101,  58, 122],\n",
              "        [ 85,  50, 122,  11,   1,  72, 122,  41, 122, 112]])"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    }
  ]
}