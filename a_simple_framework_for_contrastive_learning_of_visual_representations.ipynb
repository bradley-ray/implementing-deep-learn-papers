{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPCTvAzz3HyPRQHrAaSIRI+"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple Framework for Contrastive Learning of Visual Representations\n",
        "* [paper](https://arxiv.org/abs/2002.05709)\n",
        "* [weights](https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv1?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false)"
      ],
      "metadata": {
        "id": "RpCrlep7Ov5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "k_D7XIl0EfhR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimCLR uses ResNet-50 for the encoder model."
      ],
      "metadata": {
        "id": "TdCiHC9I6EHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HtLYWt_iOsc0"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet\n",
        "\n",
        "class TrainHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ff1 = nn.Linear(2048, 2048)\n",
        "        self.ff2 = nn.Linear(2048, 2048)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.ff1(x))\n",
        "        out = self.ff2(out)\n",
        "        return out\n",
        "\n",
        "class LinearClassifierHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        ...\n",
        "\n",
        "class Encoder(resnet.ResNet):\n",
        "    def __init__(self, block, layers):\n",
        "        super().__init__(block, layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = torch.flatten(self.avgpool(out), 1, -1)\n",
        "        return out\n",
        "\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, head: nn.Module=None):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(resnet.Bottleneck, [3,4,6,3])\n",
        "        self.head = head\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        if self.head != None:\n",
        "            out = self.head(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimCLR(TrainHead())\n",
        "model.eval()\n",
        "\n",
        "img = torch.normal(0, 1, (1, 3, 224, 224))\n",
        "model(img).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyWM8Tl2CUvh",
        "outputId": "43f229ff-6c82-4d72-87dd-fbd46239df76"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2048])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}