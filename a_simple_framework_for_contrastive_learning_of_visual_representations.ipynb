{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH//WUp+JQ8OxNtaTT4c3t"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# A Simple Framework for Contrastive Learning of Visual Representations\n",
        "* [paper](https://arxiv.org/abs/2002.05709)\n",
        "* [weights](https://console.cloud.google.com/storage/browser/simclr-checkpoints/simclrv1?pageState=(%22StorageObjectListTable%22:(%22f%22:%22%255B%255D%22))&prefix=&forceOnObjectsSortingFiltering=false)\n",
        "\n",
        "## Notes for weights\n",
        "- pytorch: downsameple.0 is conv1x1, downsample.1 is batchnorm\n",
        "- 3,6,4,3 is number of blocks for each conv size\n",
        "- total conv layers = 53 = $(3*3) + (6*3) + (4*3) + (3*3) + 4 + 1$\n",
        "- resnet will have extra layers because not using a lot them (stop after avgpool)\n",
        "- tf uses '/' while pytorch uses '.'\n",
        "- tf uses 'batch_normalization_{num}/moving_...' (eww) while pytorch uses 'bn{num}.running...' for\n",
        "- tf uses numbering from 0..52 (again, eww) while pytorch is based on layers, so need working conversion"
      ],
      "metadata": {
        "id": "RpCrlep7Ov5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "k_D7XIl0EfhR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting and Converting Weights"
      ],
      "metadata": {
        "id": "qOSEkvqAPuZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "# convert simclr tf_weights to pytorch_weights\n",
        "\n",
        "def to_pytorch(tf_weights, model_dict):\n",
        "    torch_weights = dict()\n",
        "    for layer in tf_weights:\n",
        "        if 'Momentum' in layer:\n",
        "            continue\n",
        "\n",
        "        weights = torch.from_numpy(tf_weights[layer])\n",
        "        layer = layer.replace('/', '.')\n",
        "        layer = layer.replace('base_model', 'encoder')\n",
        "        layer = layer.replace('kernel', 'weight')\n",
        "        layer = layer.replace('moving', 'running')\n",
        "        layer = layer.replace('gamma', 'weight')\n",
        "        layer = layer.replace('beta', 'bias')\n",
        "        layer = layer.replace('variance', 'var')\n",
        "        layer = layer.replace('batch_normalization', 'bn')\n",
        "        layer = layer.replace('conv2d', 'conv')\n",
        "        layer = layer.replace('head_supervised.linear_layer.dense', 'head.ff1')\n",
        "        beg, mat, end = layer.partition('_')\n",
        "        if end != '' and end[0].isdigit():\n",
        "            b, e = beg.split('.')\n",
        "            num, end_ = end.split('.')\n",
        "            num = int(num)\n",
        "            layer_idx = 'layer'\n",
        "            # set up some variables\n",
        "            if num <= 10:   # layer 1 (10 = 3blocks * 3convs + 1)\n",
        "                layer_idx += '1'\n",
        "            elif num <= 23: # layer 2 (29 = prev + 4blocks * 3convs + 1)\n",
        "                num -= 10\n",
        "                layer_idx += '2'\n",
        "            elif num <= 42: # layer 3 (42 = prev + 6blocks * 3convs + 1)\n",
        "                num -= 23\n",
        "                layer_idx += '3'\n",
        "            else:           # layer 4 (52 = prev + 3blocks * 3convs + 1)\n",
        "                num -= 42\n",
        "                layer_idx += '4'\n",
        "\n",
        "            # change layer name accordingly\n",
        "            if num == 1 and 'conv' in layer:\n",
        "                layer = '.'.join([b, layer_idx, '0', 'downsample.0', end_])\n",
        "            elif num == 1 and 'bn' in layer:\n",
        "                layer = '.'.join([b, layer_idx, '0', 'downsample.1', end_])\n",
        "            else:\n",
        "                num -= 2\n",
        "                block, idx  = divmod(num, 3)\n",
        "                layer = '.'.join([b, layer_idx, str(block), ('conv' if 'conv' in layer else 'bn') + str(idx+1), end_])\n",
        "            \n",
        "        elif 'conv.' in layer:\n",
        "            layer = layer.replace('conv.', 'conv1.')\n",
        "        elif 'bn.' in layer:\n",
        "            layer = layer.replace('bn.', 'bn1.')\n",
        "\n",
        "        # permuting weights\n",
        "        if 'conv' in layer or 'downsample.0' in layer:\n",
        "            weights = weights.permute(3,2,0,1)\n",
        "        elif 'ff' in layer:\n",
        "            weights = weights.T\n",
        "\n",
        "\n",
        "        # print(layer)\n",
        "        assert layer in model_dict and layer not in torch_weights\n",
        "        torch_weights[layer] = weights\n",
        "    return torch_weights"
      ],
      "metadata": {
        "id": "P6LrgttzSPqn"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TODO**: probably should turn this into a python function"
      ],
      "metadata": {
        "id": "BnWchKO4aW0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finetune-10%, 1x width\n",
        "!rm -r 1x\n",
        "!gsutil -m cp -r \\\n",
        "  \"gs://simclr-checkpoints/simclrv1/finetune_10pct/1x\" \\\n",
        "  ."
      ],
      "metadata": {
        "id": "xuzjhAOaBcxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finetune-100%, 1x width\n",
        "!rm -r 1x\n",
        "!gsutil -m cp -r \\\n",
        "  \"gs://simclr-checkpoints/simclrv1/finetune_100pct/1x\" \\\n",
        "  ."
      ],
      "metadata": {
        "id": "-CAuIGsgByAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pretrained weights, 1x width\n",
        "!rm -r 1x\n",
        "!gsutil -m cp -r \\\n",
        "  \"gs://simclr-checkpoints/simclrv1/pretrain/1x\" \\\n",
        "  ."
      ],
      "metadata": {
        "id": "WABBTAf3FRKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f548bb78-bffb-4404-99c2-f47b9ec759df"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://simclr-checkpoints/simclrv1/pretrain/1x/checkpoint...\n",
            "/ [0/9 files][    0.0 B/213.3 MiB]   0% Done                                    \rCopying gs://simclr-checkpoints/simclrv1/pretrain/1x/graph.pbtxt...\n",
            "/ [0/9 files][    0.0 B/213.3 MiB]   0% Done                                    \rCopying gs://simclr-checkpoints/simclrv1/pretrain/1x/hub/saved_model.pb...\n",
            "/ [0/9 files][    0.0 B/213.3 MiB]   0% Done                                    \rCopying gs://simclr-checkpoints/simclrv1/pretrain/1x/hub/variables/variables.index...\n",
            "/ [0/9 files][    0.0 B/213.3 MiB]   0% Done                                    \rCopying gs://simclr-checkpoints/simclrv1/pretrain/1x/model.ckpt-225206.data-00000-of-00001...\n",
            "/ [0/9 files][    0.0 B/213.3 MiB]   0% Done                                    \rCopying gs://simclr-checkpoints/simclrv1/pretrain/1x/model.ckpt-225206.index...\n",
            "/ [0/9 files][    0.0 B/213.3 MiB]   0% Done                                    \rCopying gs://simclr-checkpoints/simclrv1/pretrain/1x/hub/tfhub_module.pb...\n",
            "/ [0/9 files][    0.0 B/213.3 MiB]   0% Done                                    \rCopying gs://simclr-checkpoints/simclrv1/pretrain/1x/model.ckpt-225206.meta...\n",
            "Copying gs://simclr-checkpoints/simclrv1/pretrain/1x/hub/variables/variables.data-00000-of-00001...\n",
            "- [9/9 files][213.3 MiB/213.3 MiB] 100% Done                                    \n",
            "Operation completed over 9 objects/213.3 MiB.                                    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SimCLR uses ResNet-50 for the encoder model."
      ],
      "metadata": {
        "id": "TdCiHC9I6EHc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 231,
      "metadata": {
        "id": "HtLYWt_iOsc0"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet\n",
        "\n",
        "class TrainHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ff1 = nn.Linear(2048, 2048)\n",
        "        self.ff2 = nn.Linear(2048, 2048)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.relu(self.ff1(x))\n",
        "        out = self.ff2(out)\n",
        "        return out\n",
        "\n",
        "class LinearClassifierHead(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.ff1 = nn.Linear(2048, 1000)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.ff1(x)\n",
        "        return out\n",
        "\n",
        "class Encoder(resnet.ResNet):\n",
        "    def __init__(self, block, layers):\n",
        "        super().__init__(block, layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = torch.flatten(self.avgpool(out), 1, -1)\n",
        "        return out\n",
        "\n",
        "class SimCLR(nn.Module):\n",
        "    def __init__(self, head: nn.Module=None):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(resnet.Bottleneck, [3,4,6,3])\n",
        "        self.head = head\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.encoder(x)\n",
        "        if self.head != None:\n",
        "            out = self.head(out)\n",
        "        return out\n",
        "\n",
        "    def load_pretrained_weights(self):\n",
        "        params = self.state_dict()\n",
        "        vars = map(lambda x: x[0], tf.train.list_variables('1x'))\n",
        "        \n",
        "        reader = tf.train.load_checkpoint('1x')\n",
        "        layers = {layer: reader.get_tensor(layer)\\\n",
        "                for layer in vars if layer != 'global_step'}\n",
        "        \n",
        "        loaded_params = to_pytorch(layers, params)\n",
        "        for layer in params:\n",
        "            if layer not in loaded_params:\n",
        "                loaded_params[layer] = torch.zeros_like(params[layer])\n",
        "        \n",
        "        self.load_state_dict(loaded_params)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = SimCLR(TrainHead())\n",
        "model = SimCLR(LinearClassifierHead())\n",
        "model.load_pretrained_weights()\n",
        "model.eval()\n",
        "\n",
        "img = torch.normal(0, 1, (1, 3, 224, 224))\n",
        "model(img).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyWM8Tl2CUvh",
        "outputId": "ff5d92ca-8816-4c12-b1d6-b525d5cee0e7"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1000])"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    }
  ]
}